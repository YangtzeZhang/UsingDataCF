### 文本日志收集

---

#### 简介

文本日志收集模块（简称Hyoga 系统）从数据源抽取出所需的数据，经过数据清洗，最终按照预先定义好的数据仓库模型，将数据加载到数据仓库中去。由 hyoga-flume 采集 json 格式数据，经过 storm 数据清理入库，现支持 hbase、hive、mysql、greenplum 等入库。具体结构如下图![](/assets/Hyoga 系统结构图.png)

#### ![](/assets/Hyoga-calc 数据流图.png)使用示例

采用 COMMON 任务类型，采集日志数据入库到 HBase 中。

1. 首先确定日志数据机器及目录，添加任务填写具体目录及选择机器（若机器列表没有则需要部署或配置，采集机器部署流程见下文）。

2. 添加任务后，打开『日志详情』，准备新增日志。

3. 填写相关的字段列表，其中首个字段为日志时间标识，对应『留存时间key』，系统会根据这个字段定时清理入库的数据，还需配置不同数据库的『数据留存时间』，HBase数据默认保留一个月。

4. 新建日志后，确保开启机器以及开启任务。即可在最终目标数据库，查到对应的日志数据。

![](/assets/Hyoga任务.png)

#### 具体功能

**机器管理**

机器管理，主要是对 hyoga-flume 实例部署的机器进行管理及配置，hyoga 任务需要配置一个或多个机器。每一个机器上需部署 hyoga-agent。

`日志数据采集机器需要部署hyoga-agent，并在『机器管理』配置。下载程序包，配置 host 并申请开通 kafka 集群端口权限，执行命令启动即可。`

**任务管理**

任务管理包含了 hyoga 系统的大部分功能，包括任务重跑、任务开关、日志配置等等。具体的任务类型及日志类型：

1. 任务类型：COMMON 普通分钟日志，普通分钟日志（COMMON）即源数据需要按分钟切割日志，每天生成一个目录，格式：./yyyyMMdd/\*\_HHmm.log ，例如：/data/logs/test\_log/20170505/xxx\_1419.log ；
2. 日志类型：MULTI 表示一个任务可以配置一个或多个日志。若多个日志，需要提供分区日志的相关配置，即创建任务接口的 multiKey 字段；
3. 数据类型：两种（JSON, TEXT）， 默认为 JSON 数据类型不需要多余配置。若为 TEXT 数据类型，需要提供字段分隔符以及行分隔符，即创建任务接口的 textConf 字段；
4. 数据开关：每一个日志都会有数据流开关，表示是否需要将数据持久化到不同数据库，可以打开一个或者多个。
5. 重跑任务：有时候需要重新采集日志数据，只需在『任务管理』操作中点击『重跑』，填写『重跑时间』及重跑机器即可。入库HBase的日志数据，不需要清空HBase，系统会将重复的数据覆盖掉。



